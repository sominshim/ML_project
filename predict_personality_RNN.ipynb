{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_personality_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjHr6EjNHNOtILuIudseGl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sominshim/Predicting_Personality_through_Text/blob/Ujin/predict_personality_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM7jItnRwobQ"
      },
      "source": [
        "# MBTI(Myers-Briggs Type Indicator) RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfsxXYquUOk7"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CdSzDMFY4Cg",
        "outputId": "93c61c09-15a3-4596-bb84-a0ee120ba7b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"버전: \", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "버전:  2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2KRWQUnw0jy"
      },
      "source": [
        "### load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onUX4hGsZBG1",
        "outputId": "c2606d1e-2367-4101-beb0-d0f4a359f110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#드라이브에 접근할 수 있도록 아래 코드 입력\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-etk7v1U1DG"
      },
      "source": [
        "#불러올 파일의 경로를 filename 변수에 저장\n",
        "filename = '/content/drive/My Drive/mbti_1.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27DRHE_4U3ku",
        "outputId": "d417dbb9-7d44-425f-eeed-6dc27a74d124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#pandas read_csv로 불러오기\n",
        "import pandas as pd\n",
        "data = pd.read_csv(filename)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Muqv03Upjk",
        "outputId": "148ca307-076b-434c-eab6-5cbddc5f1c89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = data\n",
        "print(text.shape)\n",
        "\n",
        "print(text[0:5])\n",
        "print(text.iloc[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8675, 2)\n",
            "   type                                              posts\n",
            "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
            "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
            "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
            "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
            "4  ENTJ  'You're fired.|||That's another silly misconce...\n",
            "type                                                  INTP\n",
            "posts    'Good one  _____   https://www.youtube.com/wat...\n",
            "Name: 2, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v9MJ5Piw5GB"
      },
      "source": [
        "### Preprocessing labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwMkzZxixJ7H"
      },
      "source": [
        "mbti one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w_M09T6Ur2t",
        "outputId": "c76a801c-e9b5-471a-955e-675ca110f477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# One hot encode labels\n",
        "labels=text.index.tolist()\n",
        "encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
        "labels=encoder.fit_transform(labels)\n",
        "labels=np.array(labels)\n",
        "print(labels[50:55])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx6vaGq3VRLp"
      },
      "source": [
        "mbti_dict={0:'ENFJ',1:'ENFP',2:'ENTJ',3:'ENTP',4:'ESFJ',5:'ESFP',6:'ESTJ',7:'ESTP',8:'INFJ',9:'INFP',10:'INTJ',11:'INTP',12:'ISFJ',13:'ISFP',14:'ISFP',15:'ISTP'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-TColIfVb8J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukGsT1xUVeBP"
      },
      "source": [
        "### Preprocessing posts\n",
        "We can see that the posts are very noisy, so they need to be cleaned. For this I'm doing the following:\n",
        "\n",
        "\n",
        "Converting all letters to lowercase.\n",
        "\n",
        "Remove '|||'\n",
        "\n",
        "Removing punctuation.\n",
        "\n",
        "Removing URLs, links etc..\n",
        "\n",
        "Convert words to integers\n",
        "\n",
        "We'll leave unicode emojis alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIskpS-YVfQp"
      },
      "source": [
        "import re\n",
        "\n",
        "# Function to clean data ... will be useful later\n",
        "def post_cleaner(post):\n",
        "    \"\"\"cleans individual posts`.\n",
        "    Args:\n",
        "        post-string\n",
        "    Returns:\n",
        "         cleaned up post`.\n",
        "    \"\"\"\n",
        "    # Covert all uppercase characters to lower case\n",
        "    post = post.lower() \n",
        "    \n",
        "    # Remove |||\n",
        "    post=post.replace('|||',\"\") \n",
        "\n",
        "    # Remove URLs, links etc\n",
        "    post = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '', post, flags=re.MULTILINE) \n",
        "    # This would have removed most of the links but probably not all \n",
        "\n",
        "    # Remove puntuations \n",
        "    puncs1=['@','#','$','%','^','&','*','(',')','-','_','+','=','{','}','[',']','|','\\\\','\"',\"'\",';',':','<','>','/']\n",
        "    for punc in puncs1:\n",
        "        post=post.replace(punc,'') \n",
        "\n",
        "    puncs2=[',','.','?','!','\\n']\n",
        "    for punc in puncs2:\n",
        "        post=post.replace(punc,' ') \n",
        "    # Remove extra white spaces\n",
        "    post=re.sub( '\\s+', ' ', post ).strip()\n",
        "    return post"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTec5aXlVkoA"
      },
      "source": [
        "# Clean up posts\n",
        "# Covert pandas dataframe object to list. I prefer using lists for prepocessing. \n",
        "posts=text.posts.tolist()\n",
        "posts=[post_cleaner(post) for post in posts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbzyNmZoxU7V",
        "outputId": "4beb962c-65a6-4359-95b4-5eedb6dd5efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "posts[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'and intj moments sportscenter not top ten plays prankswhat has been the most lifechanging experience in your life on repeat for most of today may the perc experience immerse you the last thing my infj friend posted on his facebook before committing suicide the next day rest in peace~ enfj7 sorry to hear of your distress its only natural for a relationship to not be perfection all the time in every moment of existence try to figure the hard times as times of growth as 84389 84390 welcome and stuff game set match prozac wellbrutin at least thirty minutes of moving your legs and i dont mean moving them while sitting in your same desk chair weed in moderation maybe try edibles as a healthier alternative basically come up with three items youve determined that each type or whichever types you want to do would more than likely use given each types cognitive functions and whatnot when left by all things in moderation sims is indeed a video game and a good one at that note a good one at that is somewhat subjective in that i am not completely promoting the death of any given sim dear enfp what were your favorite video games growing up and what are your now current favorite video games cool appears to be too late sadtheres someone out there for everyone wait i thought confidence was a good thing i just cherish the time of solitude bc i revel within my inner world more whereas most other time id be workin just enjoy the me time while you can dont worry people will always be around to yo entp ladies if youre into a complimentary personality well hey when your main social outlet is xbox live conversations and even then you verbally fatigue quickly i really dig the part from 146 to 250http because this thread requires it of me get high in backyard roast and eat marshmellows in backyard while conversing over something intellectual followed by massages and kisses for too many bs in that sentence how could you think of the b banned for watching movies in the corner with the dunces banned because health class clearly taught you nothing about peer pressure banned for a whole host of reasons two baby deer on left and right munching on a beetle in the middle 2 using their own blood two cavemen diary todays latest happenings on their designated cave diary wall 3 i see it as a pokemon world an infj society everyone becomes an optimist49142http all artists are artists because they draw its the idea that counts in forming something of your own like a signature welcome to the robot ranks person who downed my selfesteem cuz im not an avid signature artist like herself proudbanned for taking all the room under my bed ya gotta learn to share with the roaches for being too much of a thundering grumbling kind of storm yep ahh old high school music i havent heard in ages failed a public speaking class a few years ago and ive sort of learned what i could do better were i to be in that position again a big part of my failure was just overloading myself with too i like this persons mentality hes a confirmed intj by the way to the denver area and start a new life for myself'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfBq9UHEVm2k"
      },
      "source": [
        "# Count total words\n",
        "from collections import Counter\n",
        "\n",
        "word_count=Counter()\n",
        "for post in posts:\n",
        "    word_count.update(post.split(\" \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwEO2uaIVoqj",
        "outputId": "a40e9fe9-b1eb-4162-a579-72b8f2b00e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Size of the vocabulary available to the RNN\n",
        "vocab_len=len(word_count)\n",
        "print(vocab_len)\n",
        "\n",
        "print(len(posts[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172984\n",
            "3094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTwjP4_9xuBI"
      },
      "source": [
        "### convert words to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Njk0x-ZVss6",
        "outputId": "56c6f81d-45cd-4dde-b155-bbec4283e54f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a look up table \n",
        "vocab = sorted(word_count, key=word_count.get, reverse=True)\n",
        "# Create your dictionary that maps vocab words to integers here\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "\n",
        "posts_ints=[]\n",
        "for post in posts:\n",
        "    posts_ints.append([vocab_to_int[word] for word in post.split()])\n",
        "\n",
        "print(posts_ints[0])\n",
        "print(len(posts_ints[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 141, 1287, 61293, 22, 703, 1850, 2069, 61294, 89, 72, 2, 84, 13390, 286, 11, 39, 108, 24, 2176, 14, 84, 6, 375, 196, 2, 723, 286, 12342, 7, 2, 241, 115, 12, 133, 148, 574, 24, 134, 1035, 185, 5881, 2140, 2, 459, 189, 762, 11, 61295, 61296, 279, 3, 416, 6, 39, 7396, 34, 86, 814, 14, 4, 238, 3, 22, 20, 3969, 43, 2, 59, 11, 217, 475, 6, 1558, 154, 3, 524, 2, 205, 242, 26, 242, 6, 2559, 26, 61297, 61298, 308, 5, 274, 492, 712, 1216, 12655, 61299, 41, 257, 7322, 987, 6, 1077, 39, 3300, 5, 1, 31, 161, 1077, 64, 169, 1108, 11, 39, 130, 2803, 3858, 1989, 11, 7024, 150, 154, 28515, 26, 4, 5882, 2233, 510, 211, 62, 16, 565, 3459, 443, 2804, 8, 309, 95, 32, 6508, 218, 7, 81, 3, 33, 49, 47, 90, 408, 221, 626, 309, 218, 630, 342, 5, 4236, 40, 532, 73, 43, 76, 11, 7024, 5185, 9, 1027, 4, 464, 492, 5, 4, 75, 46, 41, 8, 940, 4, 75, 46, 41, 8, 9, 833, 1489, 11, 8, 1, 56, 22, 354, 10262, 2, 684, 6, 111, 626, 11286, 613, 194, 35, 103, 39, 417, 464, 568, 1120, 62, 5, 35, 21, 39, 92, 954, 417, 464, 568, 389, 2038, 3, 20, 70, 688, 61300, 98, 52, 63, 14, 206, 641, 1, 136, 1226, 27, 4, 75, 115, 1, 29, 7025, 2, 59, 6, 3799, 2690, 1, 13798, 807, 12, 1200, 191, 47, 2517, 84, 77, 59, 135, 20, 24052, 29, 305, 2, 17, 59, 169, 7, 42, 31, 789, 38, 85, 93, 20, 149, 3, 2713, 237, 2772, 30, 99, 114, 4, 12021, 243, 71, 415, 40, 39, 778, 303, 5336, 9, 8314, 301, 927, 5, 91, 88, 7, 3449, 9909, 988, 1, 48, 3067, 2, 251, 55, 16828, 3, 61301, 54, 19, 152, 2070, 10, 6, 17, 53, 289, 11, 7914, 10067, 5, 663, 28516, 11, 7914, 169, 7634, 143, 80, 1368, 2017, 73, 16829, 5, 5288, 14, 70, 138, 2511, 11, 8, 1638, 51, 105, 7, 37, 6, 2, 1186, 2805, 14, 556, 717, 11, 2, 2174, 16, 2, 44462, 2805, 54, 1295, 570, 934, 1738, 7, 273, 36, 5789, 1731, 2805, 14, 4, 340, 5260, 6, 661, 177, 1223, 7915, 24, 532, 5, 122, 31809, 24, 4, 20075, 11, 2, 810, 176, 360, 100, 195, 1588, 177, 19078, 5151, 4506, 3057, 15607, 24, 100, 11517, 4097, 5151, 1437, 235, 1, 82, 10, 26, 4, 3171, 191, 25, 133, 742, 206, 1426, 25, 61302, 43, 2371, 21, 2371, 54, 45, 1235, 34, 2, 252, 8, 2750, 11, 5531, 80, 6, 39, 195, 23, 4, 2111, 308, 3, 2, 2537, 8212, 126, 66, 36641, 12, 2867, 2228, 18, 22, 25, 7714, 2111, 1662, 23, 1796, 61303, 14, 447, 43, 2, 585, 646, 12, 886, 1196, 1398, 426, 3, 490, 16, 2, 19079, 14, 69, 70, 68, 6, 4, 36642, 44463, 168, 6, 4135, 1088, 2944, 321, 289, 222, 278, 1, 324, 489, 11, 2395, 1831, 4, 941, 777, 570, 4, 170, 156, 319, 5, 57, 374, 6, 672, 35, 1, 105, 33, 174, 103, 1, 3, 20, 11, 8, 1197, 276, 4, 327, 251, 6, 12, 2560, 27, 29, 26049, 101, 16, 70, 1, 23, 19, 1328, 3111, 246, 4, 2680, 141, 73, 2, 79, 3, 2, 11759, 1188, 5, 293, 4, 209, 108, 14, 101]\n",
            "566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRR2lPQfx8LM"
      },
      "source": [
        "### Make posts uniform\n",
        "\n",
        "We can see that the lengths of the posts aren't uniform, so we'll limit number of words in each post to 1000.For posts with less than 1000 words, we'll pad with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJeY2ix8Vy8M",
        "outputId": "49ac6ead-3f46-409c-aeb7-292f475c6f06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "posts_lens = Counter([len(x) for x in posts])\n",
        "print(\"Zero-length reviews: {}\".format(posts_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(posts_lens)))\n",
        "print(\"Minimum review length: {}\".format(min(posts_lens)))\n",
        "\n",
        "seq_len = 500\n",
        "features=np.zeros((len(posts_ints),seq_len),dtype=int)\n",
        "for i, row in enumerate(posts_ints):\n",
        "    features[i, -len(row):] = np.array(row)[:seq_len]\n",
        "print(features[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length reviews: 0\n",
            "Maximum review length: 9588\n",
            "Minimum review length: 13\n",
            "[[   5  141 1287 ...  222  278    1]\n",
            " [  18  751    2 ...    2 1660 4189]\n",
            " [  75   46  386 ...   24 2234   75]\n",
            " ...\n",
            " [   1  259    3 ...   17  631    3]\n",
            " [  18   22  120 ... 4330  659   11]\n",
            " [  11   19 1197 ...   47 2496  112]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nylLsBl5yUYa"
      },
      "source": [
        "Preparing tranining, test and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjQW-nKNV1qA",
        "outputId": "cdc27d3e-3949-4a6c-ec0e-58993d64cfad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Split data into training, test and validation\n",
        "\n",
        "split_frac = 0.8\n",
        "\n",
        "num_ele=int(split_frac*len(features))\n",
        "rem_ele=len(features)-num_ele\n",
        "train_x, val_x = features[:num_ele],features[num_ele:int(rem_ele/2)+num_ele]\n",
        "train_y, val_y = labels[:num_ele],labels[num_ele:int(rem_ele/2)+num_ele]\n",
        "\n",
        "test_x = features[num_ele+int(rem_ele/2):]\n",
        "test_y = labels[num_ele+int(rem_ele/2):]\n",
        "\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(6940, 500) \n",
            "Validation set: \t(867, 500) \n",
            "Test set: \t\t(868, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpF5Z8ytV764"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ied3__Kr-iX6",
        "outputId": "560da518-7df5-4987-8c03-4f18da16bf91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'labels:0' shape=(None, None) dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW4TTYsgV4jS"
      },
      "source": [
        "lstm_size = 256\n",
        "lstm_layers = 1\n",
        "batch_size = 256\n",
        "learning_rate = 0.01\n",
        "embed_dim=250"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkuR7RsxV9rT"
      },
      "source": [
        "n_words = len(vocab_to_int) + 1 # Adding 1 because we use 0's for padding, dictionary started at 1\n",
        "\n",
        "# Create the graph object 새 그래프 생성\n",
        "graph = tf.Graph()\n",
        "\n",
        "# Add nodes to the graph 노드추가\n",
        "with graph.as_default():\n",
        "    input_data = tf.compat.v1.placeholder(tf.int32, [None, None], name='inputs')  # placeholder (dtype : 데이터 타입, shape : 입력 데이터의 형태상수or다차원배열, name : 해당 placeholder의 이름)\n",
        "    labels_ = tf.compat.v1.placeholder(tf.int32, [None, None], name='labels')\n",
        "    keep_prob = tf.compat.v1.placeholder(tf.float32, name='keep_prob')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5YmueqJV_kD",
        "outputId": "e7959185-cca7-42e6-90e5-350a5f0b40b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Embedding\n",
        "with graph.as_default():\n",
        "    embedding= tf.Variable(tf.random.uniform(shape=(n_words,embed_dim),minval=-1,maxval=1))\n",
        "    embed=tf.nn.embedding_lookup(embedding,input_data) #텐서 목록에서 병렬 조회 수행 (params:완전한 임베딩 텐서를 나타내는 단일 텐서 또는 \"div\"파티션 전략에 따라 분할 된 임베딩 텐서를 나타내는 첫 번째 차원을 제외하고 모두 동일한 형태의 텐서 목록입니다, ids : Tensor유형 int32또는 int64ID를 포함하는가에 조회 할 수 있습니다 params)\n",
        "    print(embed.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, None, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_lLZzweXiQs"
      },
      "source": [
        "#pip install tensorflow-gpu==1.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQjXLpmpWThS"
      },
      "source": [
        "# LSTM cell\n",
        "with graph.as_default():\n",
        "    # create basic LSTM cell\n",
        "    lstm = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(lstm_size) #num_units : 훈련 시작시 망각의 규모를 줄이기 위해 망각 게이트의 편향에 forget_bias (기본값 : 1)를 추가\n",
        "    \n",
        "    # Add dropout to the cell\n",
        "    drop = tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
        "    \n",
        "    # Stack up multiple LSTM layers, for deep learning\n",
        "    cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([drop]* lstm_layers)\n",
        "    \n",
        "    # Getting an initial state of all zeros\n",
        "    initial_state = cell.zero_state(batch_size, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM_sD75PWkJK"
      },
      "source": [
        "with graph.as_default():\n",
        "    outputs,final_state=tf.compat.v1.nn.dynamic_rnn(cell,embed,dtype=tf.float32 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUa1yT64B_H",
        "outputId": "b7a0917d-8dec-4ed8-e775-6a0820909ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.compat.v1.disable_eager_execution() # need to disable eager in TF2.x\n",
        "# Build a graph.\n",
        "a = tf.constant(5.0)\n",
        "b = tf.constant(6.0)\n",
        "c = a * b\n",
        "\n",
        "# Launch the graph in a session.\n",
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "# Evaluate the tensor `c`.\n",
        "print(sess.run(c)) # prints 30.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMy1gKly9lAf"
      },
      "source": [
        "labels_ = tf.compat.v1.placeholder(tf.int32, [No, None], name='labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_sqwj4B7P8D",
        "outputId": "f5a3e1fd-2382-4eb4-a5d9-e8e52ec49b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "sess.run(labels_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3669\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3670\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3748\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"labels:0\", shape=(None, None), dtype=int32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-254-c8160b20c0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1166\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 312\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    313\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
            "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'labels:0' shape=(None, None) dtype=int32> cannot be interpreted as a Tensor. (Tensor Tensor(\"labels:0\", shape=(None, None), dtype=int32) is not an element of this graph.)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re6q08mn5eGM",
        "outputId": "e7bb1917-58da-4716-8bc5-e9511ad10ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "with graph.as_default():\n",
        "    \n",
        "    pre = tf.keras.layers.Dense(16,  activation = tf.nn.relu)(outputs[:,-1])\n",
        "    predictions=tf.keras.layers.Dense(16, activation='softmax')(pre)\n",
        "    \n",
        "    cost = tf.compat.v1.losses.mean_squared_error(labels_,predictions)\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate).minimize(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-247-283fd3395ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[1;32m    374\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 375\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    894\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         raise ValueError(\"Passed in object of type {}, not tf.Tensor\".format(\n\u001b[0;32m--> 896\u001b[0;31m             type(t)))\n\u001b[0m\u001b[1;32m    897\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         logging.log_first_n(\n",
            "\u001b[0;31mValueError\u001b[0m: Passed in object of type <class 'int'>, not tf.Tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hOL7upLcL7m"
      },
      "source": [
        "with graph.as_default():\n",
        "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvBl18SMA0mz"
      },
      "source": [
        "def get_batches(x, y, batch_size=100):    \n",
        "    n_batches = len(x)//batch_size\n",
        "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
        "    for ii in range(0, len(x), batch_size):\n",
        "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60d28Yx-A4t1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m17WrENxA1_5",
        "outputId": "dc0f8a69-4c2e-4a11-cdad-b21db0e77e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "with graph.as_default():\n",
        "    saver = tf.compat.v1.train.Saver()\n",
        "\n",
        "with tf.compat.v1.Session(graph=graph) as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    iteration = 1\n",
        "    for e in range(epochs):\n",
        "        state = sess.run(initial_state)\n",
        "        \n",
        "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
        "            feed = {input_data: x,\n",
        "                    labels_: y,\n",
        "                    keep_prob: 1.0,\n",
        "                    initial_state: state}\n",
        "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
        "            \n",
        "            if iteration%5==0:\n",
        "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
        "                      \"Iteration: {}\".format(iteration),\n",
        "                      \"Train loss: {:.3f}\".format(loss))\n",
        "\n",
        "            if iteration%25==0:\n",
        "                val_acc = []\n",
        "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
        "                for x, y in get_batches(val_x, val_y, batch_size):\n",
        "                    feed = {input_data: x,\n",
        "                            labels_: y,\n",
        "                            keep_prob: 1,\n",
        "                            initial_state: val_state}\n",
        "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
        "                    val_acc.append(batch_acc)\n",
        "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
        "            iteration +=1\n",
        "    saver.save(sess, \"checkpoints/mbti.ckpt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-248-946585e588de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     initial_state: state}\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1158\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (256, 8675) for Tensor 'labels:0', which has shape '(None, 16)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WkdzdybA5QK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}